{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictability of Features and Samples\n",
    "\n",
    "In this notebook we'll ask a basic question:\n",
    "\n",
    "How predictable are different features and samples in general?\n",
    "\n",
    "PCA makes the best possible orthogonal representation of a dataset using up to n different linear components, so it's the platonic ideal of how well a dataset is represented by a multivariate normal distribution with some covariance matrix. \n",
    "\n",
    "So let's ask ourselves, how much information can we recover from various scRNAseq datasests if we project them into a lower-dimensional subspace using PCA and then recover them? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "import pickle \n",
    "\n",
    "data_location = \"../data/aging_brain/\"\n",
    "\n",
    "young = pickle.load(open(data_location + \"aging_brain_young.pickle\",mode='rb'))\n",
    "old = pickle.load(open(data_location + \"aging_brain_old.pickle\",mode='rb'))\n",
    "\n",
    "# filtered = pickle.load(open(data_location + \"aging_brain_filtered.pickle\",mode='rb'))\n",
    "\n",
    "# batch_encoding = np.loadtxt(data_location + 'aging_batch_encoding.tsv')\n",
    "# batch_encoding = batch_encoding.astype(dtype=bool)\n",
    "\n",
    "# young_mask = np.zeros(37069,dtype=bool)\n",
    "# old_mask = np.zeros(37069,dtype=bool)\n",
    "\n",
    "# young_mask[:young.shape[0]] = True\n",
    "# old_mask[young.shape[0]:] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=25).fit(young.X)\n",
    "transformed = model.transform(young.X)\n",
    "recovered = model.inverse_transform(transformed)\n",
    "\n",
    "centered = young.X - np.mean(young.X,axis=0)\n",
    "null_squared_residual = np.power(centered,2)\n",
    "\n",
    "recovered_residual = young.X - recovered\n",
    "recovered_squared_residual = np.power(recovered_residual,2)\n",
    "\n",
    "pca_recovered_per_sample = np.sum(recovered_squared_residual,axis=1)\n",
    "pca_recovered_fraction_per_sample = np.sum(recovered_squared_residual,axis=1) / np.sum(null_squared_residual,axis=1)\n",
    "print(np.sum(null_squared_residual))\n",
    "print(np.sum(recovered_squared_residual))\n",
    "\n",
    "print(f\"Remaining variance:{(np.sum(recovered_squared_residual) / np.sum(null_squared_residual))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i,pc in enumerate(transformed.T):\n",
    "    plt.figure()\n",
    "    plt.title(i)\n",
    "    plt.scatter(*young.obsm[\"X_umap\"].T,c=pc,s=3,alpha=.4,cmap='bwr',vmin=-20,vmax=20)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# f1 = \"Ctsd\"\n",
    "# f2 = \"H2-Ab1\"\n",
    "\n",
    "# f1_index = forest.truth_dictionary.feature_dictionary[f1]\n",
    "# f2_index = forest.truth_dictionary.feature_dictionary[f2]\n",
    "\n",
    "# for i,component in enumerate(model.components_):\n",
    "#     print(f\"{i}: {f1}:{component[f1_index]},{f2}:{component[f2_index]}\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(model.components_[:,f1_index],model.components_[:,f2_index])\n",
    "# plt.plot([.2,-.2],[-.2,.2],color='red')\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_null = np.sum(null_squared_residual,axis=0) + 1\n",
    "sample_null = np.sum(null_squared_residual,axis=1) + 1\n",
    "\n",
    "pca_feature_error = np.sum(recovered_squared_residual,axis=0) + 1\n",
    "pca_feature_remaining = pca_feature_error/feature_null\n",
    "\n",
    "pca_sample_error = np.sum(recovered_squared_residual,axis=1) + 1\n",
    "pca_sample_remaining = pca_sample_error / sample_null\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fraction of Variance Unexplained, Per Feature\")\n",
    "plt.hist(pca_feature_remaining,bins=50)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fraction of Variance Unexplained, Per Sample\")\n",
    "plt.hist(pca_sample_remaining,bins=50)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA Variance Unexplained:{np.sum(recovered_squared_residual)/np.sum(null_squared_residual)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_null = np.sum(np.abs(centered),axis=0) + 1\n",
    "sample_null = np.sum(np.abs(centered),axis=1) + 1\n",
    "\n",
    "pca_feature_error = np.sum(np.abs(recovered_residual),axis=0) + 1\n",
    "pca_feature_remaining = pca_feature_error/feature_null\n",
    "\n",
    "pca_sample_error = np.sum(np.abs(recovered_residual),axis=1) + 1\n",
    "pca_sample_remaining = pca_sample_error / sample_null\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fraction of Variance Unexplained, Per Feature\")\n",
    "plt.hist(pca_feature_remaining,bins=50)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fraction of Variance Unexplained, Per Sample\")\n",
    "plt.hist(pca_sample_remaining,bins=50)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "data_location = \"../data/aging_brain/\"\n",
    "\n",
    "forest = tr.Forest.load(data_location + 'scanpy_cmp_aging_brain_true_l1')\n",
    "forest.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_residuals = forest.young_predicitons.residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest_squared_residuals = np.power(forest_residuals,2)\n",
    "\n",
    "# forest_feature_error = np.sum(forest_squared_residuals,axis=0) + 1\n",
    "# forest_feature_remaining = forest_feature_error/feature_null\n",
    "\n",
    "# forest_sample_error = np.sum(forest_squared_residuals,axis=1) + 1\n",
    "# forest_sample_remaining = forest_sample_error/sample_null\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Fraction of Variance Unexplained, Per Feature\")\n",
    "# plt.hist(forest_feature_remaining,bins=50)\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Fraction of Variance Unexplained, Per Sample\")\n",
    "# plt.hist(forest_sample_remaining,bins=50)\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.xlabel(\"Fraction of Variance Unexplained\")\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Forest Variance Unexplained:{np.sum(forest_squared_residuals)/np.sum(null_squared_residual)}\")\n",
    "\n",
    "\n",
    "# delta_sort = np.argsort(pca_feature_remaining-forest_feature_remaining)\n",
    "\n",
    "# print(f\"PCA best:{forest.output_features[delta_sort[:20]]}\")\n",
    "# print(f\"Forest best:{forest.output_features[delta_sort[-20:]]}\")\n",
    "\n",
    "# for fb in delta_sort[-20:]:\n",
    "#     print(f\"Forest best: {forest.output_features[fb]}\")\n",
    "#     print(f\"Forest: {forest_feature_remaining[fb]}\")\n",
    "#     print(f\"PCA:{pca_feature_remaining[fb]}\")\n",
    "\n",
    "# ctsd_index = forest.truth_dictionary.feature_dictionary[\"Ctsd\"]\n",
    "\n",
    "# print(forest_feature_remaining[ctsd_index])\n",
    "# print(pca_feature_remaining[ctsd_index])\n",
    "\n",
    "# feature_mean = np.mean(young.X,axis=0)\n",
    "# feature_mean.shape\n",
    "\n",
    "h2_index = forest.truth_dictionary.feature_dictionary[\"H2-Ab1\"]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*forest.tsne_coordinates.T,c=recovered_residual[:,h2_index],s=2,cmap='bwr')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Cat 1a,:  S100a9, S100a8, Wfdc21,Retnlg, Lcn2,Ngp,Camp,Mmp8,Hp, Ltf, Slpi, Trem3\n",
    "# Cat 1b: Plac8, \n",
    "# Cat 1c: H2-Eb1,H2-Aa,H2-Ab1,\n",
    "\n",
    "\n",
    "# Cat 2a: Slc22a6,Slc6a13,Fmod\n",
    "\n",
    "# Cat3: Myoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.title(\"Fraction of Variance Unexplained Per Feature, Forest Vs PCA\")\n",
    "plt.scatter(pca_feature_remaining,forest_feature_remaining,s=3,c=feature_mean)\n",
    "plt.colorbar(label=\"Mean Expression\")\n",
    "plt.plot([0,1],[0,1],color='red')\n",
    "plt.xlabel(\"PCA FVU\")\n",
    "plt.ylabel(\"Forest FVU\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.title(\"Fraction of Variance Unexplained Per Sample, Forest Vs PCA\")\n",
    "plt.scatter(pca_sample_remaining,forest_sample_remaining,s=3)\n",
    "plt.plot([0,1],[0,1],color='red')\n",
    "plt.xlabel(\"PCA FVU\")\n",
    "plt.ylabel(\"Forest FVU\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Forest Error Vs PCA Error\")\n",
    "plt.scatter(*young.obsm[\"X_umap\"].T,s=2,c=forest_sample_remaining-pca_sample_remaining,cmap='seismic',vmin=-.5,vmax=.5)\n",
    "plt.colorbar(label=\"Forest FVU - PCA FVU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene = \"Hp\"\n",
    "gene_index = forest.truth_dictionary.feature_dictionary[gene]\n",
    "\n",
    "print(forest_feature_remaining[gene_index])\n",
    "print(pca_feature_remaining[gene_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
